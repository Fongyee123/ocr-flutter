{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d37296-49ae-4ff6-97a2-7eae2d890a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/04/15 10:12:45] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\USER\\\\anaconda3\\\\envs\\\\ocr_env\\\\Lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 10:12:48,291] [    INFO] _internal.py:97 - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.19.2.86:5000\n",
      "[2025-04-15 10:12:48,292] [    INFO] _internal.py:97 - \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "[2025-04-15 10:12:48,299] [    INFO] _internal.py:97 -  * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "import paddle\n",
    "from flask_cors import CORS  # Enable CORS to allow mobile devices to connect\n",
    "import difflib  # For similarity ratio calculation\n",
    "\n",
    "# Force PaddleOCR to use CPU\n",
    "paddle.set_device('cpu')  \n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS to avoid cross-origin issues\n",
    "\n",
    "# Initialize OCR model\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=False)\n",
    "\n",
    "# Helper functions for evaluation metrics\n",
    "\n",
    "def word_accuracy(ocr_text, ground_truth):\n",
    "    ocr_words = ocr_text.split()\n",
    "    ground_truth_words = ground_truth.split()\n",
    "    correct = sum(1 for w1, w2 in zip(ocr_words, ground_truth_words) if w1 == w2)\n",
    "    return correct / len(ground_truth_words) if ground_truth_words else 0\n",
    "\n",
    "def char_accuracy(ocr_text, ground_truth):\n",
    "    ocr_chars = ''.join(ocr_text.split())\n",
    "    ground_truth_chars = ''.join(ground_truth.split())\n",
    "    correct = sum(1 for c1, c2 in zip(ocr_chars, ground_truth_chars) if c1 == c2)\n",
    "    return correct / len(ground_truth_chars) if ground_truth_chars else 0\n",
    "\n",
    "def similarity_ratio(ocr_text, ground_truth):\n",
    "    return difflib.SequenceMatcher(None, ocr_text, ground_truth).ratio()\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_image():\n",
    "    if 'image' not in request.files:\n",
    "        return jsonify({'error': 'No image uploaded'}), 400\n",
    "\n",
    "    file = request.files['image']\n",
    "    image_bytes = np.frombuffer(file.read(), np.uint8)\n",
    "    image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
    "\n",
    "    if image is None:\n",
    "        return jsonify({'error': 'Invalid image file'}), 400\n",
    "\n",
    "    # Convert to grayscale and apply adaptive thresholding for better OCR\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresholded = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                        cv2.THRESH_BINARY, 11, 2)\n",
    "    image_rgb = cv2.cvtColor(thresholded, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Perform OCR\n",
    "    result = ocr.ocr(image_rgb, cls=True)\n",
    "    \n",
    "    if not result:\n",
    "        return jsonify({'error': 'No text detected'}), 200\n",
    "\n",
    "    detected_text = [{'text': word[1][0], 'confidence': word[1][1]} for line in result for word in line]\n",
    "    ocr_text = ' '.join([word[1][0] for line in result for word in line])\n",
    "\n",
    "    # For evaluation, ground truth text should be provided, it can be a static string or passed with the request\n",
    "    ground_truth = request.form.get('ground_truth', '').strip()  # Example of receiving ground truth with the request\n",
    "\n",
    "    # If ground truth is provided, calculate the evaluation metrics\n",
    "    metrics = {}\n",
    "    if ground_truth:\n",
    "        metrics = {\n",
    "            'word_accuracy': word_accuracy(ocr_text, ground_truth),\n",
    "            'char_accuracy': char_accuracy(ocr_text, ground_truth),\n",
    "            'similarity_ratio': similarity_ratio(ocr_text, ground_truth)\n",
    "        }\n",
    "\n",
    "    print(\"ðŸ” OCR Detected Text:\", detected_text)  # Debugging log\n",
    "\n",
    "    return jsonify({\n",
    "        'detected_text': detected_text,\n",
    "        'metrics': metrics\n",
    "    })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f375dd-84cb-46d4-99df-7c76fc5a128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/13 11:02:46] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=True, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\USER\\\\anaconda3\\\\envs\\\\ocr_env\\\\Lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/03/13 11:02:46] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2025/03/13 11:02:51] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2025/03/13 11:02:59] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "(PreconditionNotMet) The third-party dynamic library (cudnn64_8.dll) that Paddle depends on is not configured correctly. (error code is 126)\n  Suggestions:\n  1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\n  2. Configure third-party dynamic library environment variables as follows:\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\n  - Windows: set PATH by `set PATH=XXX; (at ..\\paddle\\phi\\backends\\dynload\\dynamic_loader.cc:312)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpaddleocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PaddleOCR\n\u001b[0;32m      2\u001b[0m ocr \u001b[38;5;241m=\u001b[39m PaddleOCR()\n\u001b[1;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m ocr\u001b[38;5;241m.\u001b[39mocr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpicture.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ocr_env\\Lib\\site-packages\\paddleocr\\paddleocr.py:766\u001b[0m, in \u001b[0;36mPaddleOCR.ocr\u001b[1;34m(self, img, det, rec, cls, bin, inv, alpha_color, slice)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs:\n\u001b[0;32m    765\u001b[0m     img \u001b[38;5;241m=\u001b[39m preprocess_image(img)\n\u001b[1;32m--> 766\u001b[0m     dt_boxes, rec_res, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(img, \u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mslice\u001b[39m)\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dt_boxes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rec_res:\n\u001b[0;32m    768\u001b[0m         ocr_res\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ocr_env\\Lib\\site-packages\\paddleocr\\tools\\infer\\predict_system.py:109\u001b[0m, in \u001b[0;36mTextSystem.__call__\u001b[1;34m(self, img, cls, slice)\u001b[0m\n\u001b[0;32m    107\u001b[0m     elapse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(elapsed)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 109\u001b[0m     dt_boxes, elapse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_detector(img)\n\u001b[0;32m    111\u001b[0m time_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdet\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m elapse\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dt_boxes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ocr_env\\Lib\\site-packages\\paddleocr\\tools\\infer\\predict_det.py:396\u001b[0m, in \u001b[0;36mTextDetector.__call__\u001b[1;34m(self, img, use_slice)\u001b[0m\n\u001b[0;32m    394\u001b[0m         elapse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sub_elapse\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 396\u001b[0m     dt_boxes, elapse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(img)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dt_boxes, elapse\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ocr_env\\Lib\\site-packages\\paddleocr\\tools\\infer\\predict_det.py:254\u001b[0m, in \u001b[0;36mTextDetector.predict\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_tensors, input_dict)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_tensor\u001b[38;5;241m.\u001b[39mcopy_from_cpu(img)\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    256\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ocr_env\\Lib\\site-packages\\paddle\\inference\\wrapper.py:52\u001b[0m, in \u001b[0;36mtensor_copy_from_cpu\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mSupport input type check based on tensor.copy_from_cpu.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     51\u001b[0m ):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copy_from_cpu_bind(data)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn copy_from_cpu, we only support numpy ndarray and list[str] data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: (PreconditionNotMet) The third-party dynamic library (cudnn64_8.dll) that Paddle depends on is not configured correctly. (error code is 126)\n  Suggestions:\n  1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\n  2. Configure third-party dynamic library environment variables as follows:\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\n  - Windows: set PATH by `set PATH=XXX; (at ..\\paddle\\phi\\backends\\dynload\\dynamic_loader.cc:312)\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "ocr = PaddleOCR()\n",
    "result = ocr.ocr('picture.png', cls=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0828a-4463-48cd-80e2-402e68c990eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (OCR)",
   "language": "python",
   "name": "ocr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
